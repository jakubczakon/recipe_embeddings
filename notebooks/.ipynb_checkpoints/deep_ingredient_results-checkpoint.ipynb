{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['MKL_NUM_THREADS'] = '4'\n",
    "os.environ['GOTO_NUM_THREADS'] = '4'\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "\n",
    "import theano\n",
    "theano.config.openmp = True\n",
    "\n",
    "os.environ['THEANO_FLAGS'] = 'device=cpu,blas.ldflags=-lblas -lgfortran'\n",
    "\n",
    "import cPickle as pickle\n",
    "\n",
    "import json\n",
    "from copy import copy\n",
    "\n",
    "from itertools import groupby,chain,tee,izip,islice\n",
    "from collections import Iterable,Counter\n",
    "from operator import itemgetter \n",
    "\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "from ipywidgets import interact\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import RSLPStemmer,SnowballStemmer\n",
    "from nltk import PunktSentenceTokenizer,FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import UnigramTagger,BigramTagger\n",
    "\n",
    "from gensim import corpora\n",
    "\n",
    "from keras.models import Sequential,model_from_json  \n",
    "from keras.layers.core import TimeDistributedDense,RepeatVector, Activation, Dropout,Dense,Flatten\n",
    "from keras.layers.recurrent import GRU, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint    \n",
    "# from keras.utils.visualize_util import plot\n",
    "import seq2seq\n",
    "from seq2seq.models import SimpleSeq2seq\n",
    "\n",
    "from utils_pack.utils import pickle_in,ensure_dir\n",
    "from utils_pack.word_embeddings_utils import IngredientDataTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test,Y_test = pickle_in(os.path.join(\"../datasets\",\"deep_learning_datasets\",\"test.pkl\"))\n",
    "dictionary = pickle_in(os.path.join(\"../datasets\",\"deep_learning_datasets\",\"dictionary.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_name = \"model_seq2seq_1\"\n",
    "model_folder = \"../models\"\n",
    "\n",
    "model = pickle_in(os.path.join(model_folder,model_name,'model_architecture.json'))\n",
    "# json_file = open(os.path.join(model_folder,model_name,\"model_architecture.json\"), 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# model = model_from_json(loaded_model_json,custom_objects={\"SimpleSeq2seq\":SimpleSeq2seq})\n",
    "# load weights into new model\n",
    "model.load_weights(os.path.join(model_folder,model_name,\"model_weights.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_text_ingredient(model,x,y):\n",
    "\n",
    "\n",
    "    ingredients_text = []\n",
    "    for i in range(x.shape[0]):\n",
    "        if x[i].tolist() != [0]*x.shape[0]:\n",
    "            ingredients_text.append(\" \".join([dictionary[j-1] for j in x[i] if j!=0]))\n",
    "    ingredients_text = \"\\n\".join(ingredients_text)\n",
    "    ground_truth_text =\" \".join([dictionary[np.argmax(word)-1] for word in y if np.argmax(word)!=0])\n",
    "    \n",
    "    prediction = model.predict_classes(x.reshape(1,x.shape[0],x.shape[1])) \n",
    "    prediction_text = \" \".join([dictionary[i-1] for i in prediction[0] if i!=0])\n",
    "    return (ingredients_text,ground_truth_text,prediction_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INGREDIENTS LIST:\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'ingredients_text' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d21203e3ce4f>\u001b[0m in \u001b[0;36mpresent_results\u001b[1;34m(nr)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"INGREDIENTS LIST:\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mingredients_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"\\nGROUND TRUTH:\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mground_truth_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'ingredients_text' referenced before assignment"
     ]
    }
   ],
   "source": [
    "def present_results(nr):\n",
    "    nr = int(nr)\n",
    "    x = X_test[nr]\n",
    "    y = Y_test[nr]\n",
    "    \n",
    "    ingredients_text,ground_truth_text,prediction_text = predict_text_ingredient(model,x,y)\n",
    "    print \"INGREDIENTS LIST:\\n\",ingredients_text\n",
    "    print \"\\nGROUND TRUTH:\\n\",ground_truth_text\n",
    "    print \"\\nPREDICTION:\\n\",prediction_text\n",
    "    \n",
    "interact(present_results,nr=\"10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
