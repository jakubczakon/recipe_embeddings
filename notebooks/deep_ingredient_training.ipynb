{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['MKL_NUM_THREADS'] = '4'\n",
    "os.environ['GOTO_NUM_THREADS'] = '4'\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "\n",
    "import theano\n",
    "theano.config.openmp = True\n",
    "\n",
    "os.environ['THEANO_FLAGS'] = 'device=cpu,blas.ldflags=-lblas -lgfortran'\n",
    "\n",
    "import cPickle as pickle\n",
    "\n",
    "import json\n",
    "from copy import copy\n",
    "\n",
    "from itertools import groupby,chain,tee,izip,islice\n",
    "from collections import Iterable,Counter\n",
    "from operator import itemgetter \n",
    "\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "from ipywidgets import interact\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import RSLPStemmer,SnowballStemmer\n",
    "from nltk import PunktSentenceTokenizer,FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import UnigramTagger,BigramTagger\n",
    "\n",
    "from gensim import corpora\n",
    "\n",
    "from keras.models import Sequential  \n",
    "from keras.layers.core import TimeDistributedDense,RepeatVector, Activation, Dropout,Dense,Flatten\n",
    "from keras.layers.recurrent import GRU, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint    \n",
    "# from keras.utils.visualize_util import plot\n",
    "\n",
    "import seq2seq\n",
    "from seq2seq.models import SimpleSeq2seq\n",
    "\n",
    "from utils_pack.utils import pickle_out,pickle_in,ensure_dir\n",
    "from utils_pack.word_embeddings_utils import IngredientDataTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ingredients = pickle_in(os.path.join(\"../datasets\",\"cozinhabrasileira\",\"dataset_ingredients.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat_ingredients = [word for ingredient in ingredients for word in ingredient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(flat_ingredients)\n",
    "dictionary.filter_extremes()\n",
    "filtered_ingredients = [[[word for word in entry if word in dictionary.values()] for entry in ingr] for ingr in ingredients]\n",
    "corpus = [[[dictionary.token2id[word]+1 for word in entry] for entry in ingr] for ingr in filtered_ingredients]\n",
    "pickle_out(os.path.join(\"../datasets\",\"deep_learning_datasets\",\"dictionary.pkl\"),dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_train,corpus_rest = train_test_split(corpus,train_size = 0.7)\n",
    "corpus_valid,corpus_test = train_test_split(corpus_rest,train_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3274, 6, 6)\n",
      "(3274, 6, 681)\n",
      "(696, 6, 6)\n",
      "(696, 6, 681)\n",
      "(691, 6, 6)\n",
      "(691, 6, 681)\n"
     ]
    }
   ],
   "source": [
    "IDG = IngredientDataTransformer(dictionary_word_count = len(dictionary),\n",
    "                              maxlen_ingredient = 6,\n",
    "                              max_ingredients = 6,\n",
    "                              runs = 5\n",
    "                             )\n",
    "X_train,Y_train = IDG.corpus_to_x_y_tensors(corpus_train,\n",
    "                                            os.path.join(\"../datasets\",\"deep_learning_datasets\",\"train.pkl\"))\n",
    "X_valid,Y_valid = IDG.corpus_to_x_y_tensors(corpus_valid,\n",
    "                                            os.path.join(\"../datasets\",\"deep_learning_datasets\",\"valid.pkl\"))\n",
    "X_test,Y_test = IDG.corpus_to_x_y_tensors(corpus_test,\n",
    "                                          os.path.join(\"../datasets\",\"deep_learning_datasets\",\"test.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_name = \"model_seq2seq_1\"\n",
    "model_folder = \"../models\"\n",
    "ensure_dir(os.path.join(model_folder,model_name))\n",
    "\n",
    "nb_word = len(dictionary)+1\n",
    "timesteps = 6\n",
    "words_in_ingredient = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = SimpleSeq2seq(input_dim=6, hidden_dim=32, output_length=6, output_dim=nb_word)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "pickle_out(os.path.join(model_folder,model_name,'model_architecture.json'),model)\n",
    "# json_string = model.to_json()\n",
    "# with open(os.path.join(model_folder,model_name,'model_architecture.json'), 'w+') as f:\n",
    "#     f.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=os.path.join(model_folder,model_name,\"model_weights.h5\")\n",
    "                               , verbose=2, save_best_only=True)\n",
    "model.fit(X_train, Y_train, \n",
    "          batch_size=16, nb_epoch=1000,\n",
    "          validation_data=(X_valid,Y_valid), \n",
    "          show_accuracy=True,verbose=2,callbacks = [checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_text_ingredient(model,x,y):\n",
    "    ingredients_text = []\n",
    "    for i in range(x.shape[0]):\n",
    "        if x[i].tolist() != [0]*x.shape[0]:\n",
    "            ingredients_text.append(\" \".join([dictionary[j-1] for j in x[i] if j!=0]))\n",
    "    ingredients_text = \"\\n\".join(ingredients_text)\n",
    "    ground_truth_text =\" \".join([dictionary[np.argmax(word)-1] for word in y if np.argmax(word)!=0])\n",
    "    prediction = model.predict_classes(x.reshape(1,x.shape[0],x.shape[1])) \n",
    "    print prediction\n",
    "    prediction_text = \" \".join([dictionary[i-1] for i in prediction[0] if i!=0])\n",
    "    return (ingredients_text,ground_truth_text,prediction_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "[[153 153 153 153 153 149]]\n",
      "INGREDIENTS LIST:\n",
      "1 xícara água\n",
      "xícara óleo milho\n",
      "1 xícara farinha trigo integral\n",
      "3 colheres sopa açúcar mascavo\n",
      "1 colher chá sal\n",
      "1/2 colher sopa fermento biológico seco\n",
      "\n",
      "GROUND TRUTH:\n",
      "Talos um maço\n",
      "\n",
      "PREDICTION:\n",
      "1 1 1 1 1 gosto\n"
     ]
    }
   ],
   "source": [
    "def present_results(nr):\n",
    "    nr = int(nr)\n",
    "    x = X_test[nr]\n",
    "    y = Y_test[nr]\n",
    "    \n",
    "    ingredients_text,ground_truth_text,prediction_text = predict_text_ingredient(model,x,y)\n",
    "    print \"INGREDIENTS LIST:\\n\",ingredients_text\n",
    "    print \"\\nGROUND TRUTH:\\n\",ground_truth_text\n",
    "    print \"\\nPREDICTION:\\n\",prediction_text\n",
    "    \n",
    "interact(present_results,nr=\"10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
